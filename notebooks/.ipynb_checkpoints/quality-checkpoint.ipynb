{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now discuss masures of quality for the generated images, specifically three of them:\n",
    "\n",
    "- **BPD (Bits Per Dimension):** Measures how well a model compresses data; lower BPD means better likelihood of the data under the model. Common in likelihood-based models.\n",
    "- **FID (Fréchet Inception Distance):** Compares real and generated image distributions using features from an Inception network; lower FID means more realistic and diverse images.\n",
    "- **IS (Inception Score):** Evaluates image quality and diversity using the Inception model’s output; higher IS means images are both sharp (confident labels) and diverse (many classes).\n",
    "\n",
    "Please note that calculating FID and IS required loading an Inception V3 model, a convolutional neural network architecture that is part of the Inception family of models, developed by Google, and performing many forward passes, so this can be computatinally intensive and require some significant GPU memory, specially with larger `num_eval_samples`.\n",
    "\n",
    "Also, the first time you run evaluation, torchvision might need to download the pre-trained weights for the InceptionV3 model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start with the conditional model and, for instance, class 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f25b10bf2fa5455496a709e8064eef95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<b>Evaluation Configuration:</b>'), Dropdown(description='Dataset:', options=('mnis…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from quality_utils import get_controls\n",
    "from IPython.display import display\n",
    "\n",
    "display(get_controls())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can also be run as a standalone command. This time we'll use an conditional model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Selected Dataset: MNIST\n",
      "Selected mode: evaluate\n",
      "Selected diffusion process: ve\n",
      "Initializing VE diffusion process with sigma=25.0, T=1.0\n",
      "--- Running Model Evaluation (MNIST) ---\n",
      "Starting evaluation for model: mnist_model/ve_50_conditional.pth on MNIST\n",
      "Target Class:  for class 0\n",
      "Process: ve, Sampler: euler, Steps: 1000, Eval Samples: 100\n",
      "Loading score model...\n",
      "Evaluation will generate samples conditioned on class 0.\n",
      "[DEBUG run_evaluation] Passing to generic_load_model: num_classes=10, image_channels=3\n",
      "[DEBUG run_evaluation ENTRY] Received num_classes_eval=10, args.use_class_condition=True, load_as_conditional=True\n",
      "[DEBUG run_evaluation] Setting load_image_channels=1 for MNIST model.\n",
      "Loading model from: mnist_model/ve_50_conditional.pth\n",
      "Getting ScoreModel configured for VE process.\n",
      "Model loaded successfully.\n",
      "Loading real test dataset (MNIST)...\n",
      "Loading MNIST dataset...\n",
      "Converting MNIST to 3 channels.\n",
      "Using all 60000 MNIST training samples.\n",
      "Loading standard MNIST test set...\n",
      "Loaded MNIST test set with 10000 samples.\n",
      "Filtering real test dataset for class 0...\n",
      "Using 980 real samples for class 0.\n",
      "Generating 100 images for evaluation for class 0...\n",
      "  Generating batch of 64...\n",
      "Generating 64 images conditionally for class 0.\n",
      "Generating 64 images using VE reverse SDE...\n",
      "Sampler: euler, Steps: 1000, T_end=0.001\n",
      "Final images clamped to range (-1.0, 1.0).\n",
      "Image generation finished.\n",
      "  Generating batch of 36...\n",
      "Generating 36 images conditionally for class 0.\n",
      "Generating 36 images using VE reverse SDE...\n",
      "Sampler: euler, Steps: 1000, T_end=0.001\n",
      "Final images clamped to range (-1.0, 1.0).\n",
      "Image generation finished.\n",
      "Generated 100 images. Shape: torch.Size([100, 3, 28, 28])\n",
      "\n",
      "--- Calculating Metrics --- \n",
      "Loading InceptionV3 model...\n",
      "/home/mario/.conda/envs/Jupyter/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/mario/.conda/envs/Jupyter/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "InceptionV3 loaded.\n",
      "\n",
      "Calculating Average Loss...\n",
      "Calculating average loss...\n",
      "/home/mario/Personal/Clase/Tercero/AA3/Proyecto2/diffusion/models/score_model.py:171: UserWarning: Class conditioning enabled, but no class labels provided. Using zero embedding.\n",
      "  warnings.warn(\n",
      "Average Loss: 2134.3112\n",
      "\n",
      "Calculating FID...\n",
      "Calculating activations from DataLoader...\n",
      "Calculated activations shape: (100, 2048)\n",
      "Calculating activations from Tensor...\n",
      "Calculated activations shape: (100, 2048)\n",
      "Calculating FID using 100 samples.\n",
      "FID: 101.2455\n",
      "\n",
      "Calculating Inception Score...\n",
      "Calculating Inception Score using 100 samples...\n",
      "Inception Score: 1.5070 +/- 0.1907\n",
      "\n",
      "--- Evaluation Results (MNIST) --- \n",
      "Model: mnist_model/ve_50_conditional.pth\n",
      "Target Class Evaluated: 0\n",
      "Process: ve, Sampler: euler, Steps: 1000\n",
      "Number of Samples Used: 100\n",
      "---------------------------\n",
      "Average Loss (BPD surrogate): 2134.3112\n",
      "FID Score: 101.2455\n",
      "Inception Score: 1.5070 +/- 0.1907\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "!cd .. && python main.py \\\n",
    " --mode evaluate \\\n",
    " --dataset mnist \\\n",
    " --image_channels 3 \\\n",
    " --process ve \\\n",
    " --model_path mnist_model/ve_50_conditional.pth \\\n",
    " --use_class_condition \\\n",
    " --target_class 0 \\\n",
    " --num_eval_samples 100 \\\n",
    " --sampler euler \\\n",
    " --gen_steps 1000 \\\n",
    " --pc_snr 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see values here are worse because VE is giving worse results in this case and because we have less images on the real dataset to test against as we are filtering it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
